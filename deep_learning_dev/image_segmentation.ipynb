{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "FUTemTM5pa-w",
   "metadata": {
    "id": "FUTemTM5pa-w",
    "tags": []
   },
   "source": [
    "# Training data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "x0mXqhPMp6cQ",
   "metadata": {
    "id": "x0mXqhPMp6cQ"
   },
   "source": [
    "## Download datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xw7W59vsIg3s",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xw7W59vsIg3s",
    "outputId": "d2059742-f80a-4967-cd25-ce754c4a6a0d"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "%%sh\n",
    "cat download_data.sh\n",
    "./download_data.sh\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uKAZHoFLp-ck",
   "metadata": {
    "id": "uKAZHoFLp-ck"
   },
   "source": [
    "## Patch the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df6c1c43-97ab-44d3-9777-793a7f49e395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['reid', 'fcr', 'bcs_a', 'bcs_b', 'bcs_e', 'bcs_h', 'bcs_n', 'bcs_s', 'bcs_u', 'bcs_un', 'bcc_a', 'bcc_b', 'bcc_bh', 'bcc_e', 'bcc_h', 'bcc_n', 'bcc_s', 'bcc_u', 'bcc_un'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from deep_learning_lab.data_preparation import Orchestrator, DataStructure\n",
    "\n",
    "Orchestrator.DATASETS.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96c3e57-de71-42ff-a68a-a0b2f4311600",
   "metadata": {},
   "outputs": [],
   "source": [
    "sets_labels = [['ImageRegion'], ['TextLine'], ['TextRegion']] # Atomic labels are to be promoted\n",
    "\n",
    "# Create an instance of Orchestrator and specify the output directory structure\n",
    "orc = Orchestrator(\n",
    "    output_structure= DataStructure(dir_data= \"training_data\",\n",
    "                                    dir_images= \"images\",\n",
    "                                    dir_labels= \"labels\")\n",
    ")\n",
    "\n",
    "# Ingest any datasets and add default settings\n",
    "orc.ingestDatasets(\n",
    "    datasets= [],\n",
    "    add_defaults= True\n",
    ")\n",
    "\n",
    "# Loop through each set of labels\n",
    "for set_labels in sets_labels:\n",
    "    # Ingest the labels and prompt for additional labels if needed\n",
    "    orc.ingestLabels(\n",
    "        uniform_set_labels= set_labels,\n",
    "        prompt= False\n",
    "    )\n",
    "    \n",
    "    # Validate the labels automatically and suppress verbose output\n",
    "    orc.validate(\n",
    "        auto_yes= True,\n",
    "        verbose= 0\n",
    "    )\n",
    "    \n",
    "    # Preprocess the data by resizing images and labels\n",
    "    orc.preprocess(\n",
    "        resize= (841, 1188), # To have 1e6 pixels and tensors of same size\n",
    "        overwrite= False,\n",
    "        verbose= 2\n",
    "    )\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7jNGdu-mow2R",
   "metadata": {
    "id": "7jNGdu-mow2R"
   },
   "source": [
    "# Deep learning lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1147e6c0-294f-459f-b759-953a21f9033b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch (1.12.1)\n",
      "CUDA (11.3)\n",
      "GPU (RTX A6000)\n",
      "CUDA memory (48.69 GB)\n"
     ]
    }
   ],
   "source": [
    "import deep_learning_lab.gpu_setup as gpu\n",
    "\n",
    "# Select a CUDA device to use for computation\n",
    "gpu.cudaDeviceSelection(preselected_device= 0)\n",
    "\n",
    "# Print information about the selected CUDA device\n",
    "print(gpu.cudaInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b9589b-2b0c-433e-b81d-559962d143c7",
   "metadata": {
    "id": "GH7zWNcfqlt7",
    "tags": []
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8089c6a4-f5a8-4b38-980d-0f040a8b3650",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['TextLine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b9da508-e1a2-4484-95d7-b2e65012cbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_learning_lab import model\n",
    "\n",
    "trainer = model.Trainer(\n",
    "    labels, # a list of labels for the training data\n",
    "    workdir= \"results\", # the directory where results will be saved\n",
    "    input_dir= \"training_data\", # the directory where the training data is stored\n",
    "    train_ratio= 0.80, # the ratio of data to be used for training\n",
    "    val_ratio= 0.10 # the ratio of data to be used for validation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sreWMA6GNVfV",
   "metadata": {
    "id": "sreWMA6GNVfV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n",
      "results/TextLine/tensorboard/log\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6011 (pid 13409), started 0:01:21 ago. (Use '!kill 13409' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-9bf14c3c6c272a9e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-9bf14c3c6c272a9e\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6011;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "tensorboard_dir = trainer.tensorboard_dir\n",
    "!echo $tensorboard_dir\n",
    "#!rm -r $tensorboard_dir & mkdir -p $tensorboard_dir\n",
    "%tensorboard --logdir $tensorboard_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bc8794-d6bf-44cb-8d02-aaab32cb17eb",
   "metadata": {
    "id": "56bc8794-d6bf-44cb-8d02-aaab32cb17eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'color_labels': {'label_json_file': 'results/TextLine/training_data/classfile.json'}, 'train_dataset': {'type': 'image_csv', 'csv_filename': 'results/TextLine/training_data/train.csv', 'base_dir': 'results/TextLine/training_data', 'repeat_dataset': 4, 'compose': {'transforms': [{'type': 'fixed_size_resize', 'output_size': 1000000.0}]}}, 'val_dataset': {'type': 'image_csv', 'csv_filename': 'results/TextLine/training_data/val.csv', 'base_dir': 'results/TextLine/training_data', 'compose': {'transforms': [{'type': 'fixed_size_resize', 'output_size': 1000000.0}]}}, 'model': {'encoder': 'resnet50', 'decoder': {'decoder_channels': [512, 256, 128, 64, 32], 'max_channels': 512}}, 'metrics': [['miou', 'iou'], ['iou', {'type': 'iou', 'average': None}], 'precision'], 'optimizer': {'lr': 0.0001}, 'lr_scheduler': {'type': 'exponential', 'gamma': 0.9995}, 'val_metric': '+miou', 'early_stopping': {'patience': 4}, 'model_out_dir': 'results/TextLine/model', 'num_epochs': 100, 'evaluate_every_epoch': 5, 'batch_size': 4, 'num_data_workers': 0, 'track_train_metrics': False, 'loggers': [{'type': 'tensorboard', 'log_dir': 'results/TextLine/tensorboard/log', 'log_every': 5, 'log_images_every': 10}]} color_labels\n",
      "{'label_json_file': 'results/TextLine/training_data/classfile.json'} label_json_file\n",
      "{'train_dataset': {'type': 'image_csv', 'csv_filename': 'results/TextLine/training_data/train.csv', 'base_dir': 'results/TextLine/training_data', 'repeat_dataset': 4, 'compose': {'transforms': [{'type': 'fixed_size_resize', 'output_size': 1000000.0}]}}, 'val_dataset': {'type': 'image_csv', 'csv_filename': 'results/TextLine/training_data/val.csv', 'base_dir': 'results/TextLine/training_data', 'compose': {'transforms': [{'type': 'fixed_size_resize', 'output_size': 1000000.0}]}}, 'model': {'encoder': 'resnet50', 'decoder': {'decoder_channels': [512, 256, 128, 64, 32], 'max_channels': 512}}, 'metrics': [['miou', 'iou'], ['iou', {'type': 'iou', 'average': None}], 'precision'], 'optimizer': {'lr': 0.0001}, 'lr_scheduler': {'type': 'exponential', 'gamma': 0.9995}, 'val_metric': '+miou', 'early_stopping': {'patience': 4}, 'model_out_dir': 'results/TextLine/model', 'num_epochs': 100, 'evaluate_every_epoch': 5, 'batch_size': 4, 'num_data_workers': 0, 'track_train_metrics': False, 'loggers': [{'type': 'tensorboard', 'log_dir': 'results/TextLine/tensorboard/log', 'log_every': 5, 'log_images_every': 10}]} train_dataset\n",
      "{'val_dataset': {'type': 'image_csv', 'csv_filename': 'results/TextLine/training_data/val.csv', 'base_dir': 'results/TextLine/training_data', 'compose': {'transforms': [{'type': 'fixed_size_resize', 'output_size': 1000000.0}]}}, 'model': {'encoder': 'resnet50', 'decoder': {'decoder_channels': [512, 256, 128, 64, 32], 'max_channels': 512}}, 'metrics': [['miou', 'iou'], ['iou', {'type': 'iou', 'average': None}], 'precision'], 'optimizer': {'lr': 0.0001}, 'lr_scheduler': {'type': 'exponential', 'gamma': 0.9995}, 'val_metric': '+miou', 'early_stopping': {'patience': 4}, 'model_out_dir': 'results/TextLine/model', 'num_epochs': 100, 'evaluate_every_epoch': 5, 'batch_size': 4, 'num_data_workers': 0, 'track_train_metrics': False, 'loggers': [{'type': 'tensorboard', 'log_dir': 'results/TextLine/tensorboard/log', 'log_every': 5, 'log_images_every': 10}]} model\n",
      "{'csv_filename': 'results/TextLine/training_data/train.csv', 'base_dir': 'results/TextLine/training_data', 'repeat_dataset': 4, 'compose': {'transforms': [{'type': 'fixed_size_resize', 'output_size': 1000000.0}]}} csv_filename\n",
      "{'transforms': [{'type': 'fixed_size_resize', 'output_size': 1000000.0}]} transforms\n",
      "{'csv_filename': 'results/TextLine/training_data/val.csv', 'base_dir': 'results/TextLine/training_data', 'compose': {'transforms': [{'type': 'fixed_size_resize', 'output_size': 1000000.0}]}} csv_filename\n",
      "{'transforms': [{'type': 'fixed_size_resize', 'output_size': 1000000.0}]} transforms\n",
      "{'encoder': 'resnet50', 'decoder': {'decoder_channels': [512, 256, 128, 64, 32], 'max_channels': 512}} encoder\n",
      "{'decoder': {'decoder_channels': [512, 256, 128, 64, 32], 'max_channels': 512}} decoder\n",
      "{'decoder_channels': [512, 256, 128, 64, 32], 'max_channels': 512} decoder_channels\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00674128532409668,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "epoch 0: loss=???",
       "rate": null,
       "total": 100,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1096764c6c35484196ce915964ec5e66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 0: loss=???:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011694908142089844,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "iter=0: loss=???",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "123afb99975f4a90aa725212ce18f2fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "iter=0: loss=???: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train(\n",
    "    batch_size= 4, # the number of samples to use in each batch during training\n",
    "    epochs= 100, # the number of epochs to train the model for\n",
    "    learning_rate= 1e-4, # the rate at which the model adjusts its weights during training\n",
    "    gamma_exp_lr= 0.9995, # the decay rate for the learning rate during training\n",
    "    evaluate_every_epoch= 5, # how often to evaluate the model on the validation set during training\n",
    "    val_patience= 4, # how many epochs to wait for improvement in validation loss before early stopping\n",
    "    repeat_dataset= 4, # how many times to repeat the training data during each epoch\n",
    "    output_size= 1e6 # the size of the images\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3540b081-b034-47eb-957c-208e07c395fb",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70af0d53-d5d2-4329-a83f-7db757498833",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['TextLine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3697f33-5142-4f1c-9e0f-4a1d4933eb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_learning_lab import model\n",
    "import os\n",
    "\n",
    "# Create an instance of Predictor\n",
    "predictor = model.Predictor(\n",
    "    labels, # a list of labels for the predicted classes\n",
    "    input_dir= 'inference_data', # the directory containing the input images to predict on\n",
    "    output_dir= None, # the directory to save the predicted images to (if None, saves to 'predictions')\n",
    "    output_size= None, # the size of the predicted images (if None, uses input image size)\n",
    "    from_csv= os.path.join('training_data', 'test.csv'), # is the path to a CSV file with input image paths and labels\n",
    "    reset_input= True # whether to reset the input before starting the predictor\n",
    ")\n",
    "\n",
    "predictor.start(\n",
    "    batch_size= 4, # the number of images to process at once\n",
    "    drawRegions= True, # whether to draw regions on the images\n",
    "    cutVignettes= True, # whether to cut out vignettes from the images\n",
    "    bounding_box= False, # whether to use a bounding box or a polygon around the predicted regions\n",
    "    verbose= True # whether to print status messages\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78483179-3e4d-4b97-958b-c3398e00313a",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012ef761-25f7-4791-af0f-1476d9e70164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "assert len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5780fb90-4464-433a-920a-c3d8a64118c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ddce73-5c88-4d50-aff6-22b992d6aa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_nb = 0\n",
    "predictions = results[image_nb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bb5439-2e26-486a-b631-0dddd259d2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the regions found on the original image\n",
    "Image.fromarray(predictions['regions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0d0625-babd-472e-9fe2-20f12b469279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the probability map of the class 1\n",
    "Image.fromarray(predictions['probasMaps'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f8995f-f99a-47e7-bc7f-9697c0e105ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the regions found\n",
    "for vignette in predictions['vignettes']:\n",
    "    plt.imshow(Image.fromarray(vignette))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e41e1cf-687a-4e6c-97dc-44c0c9911176",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
